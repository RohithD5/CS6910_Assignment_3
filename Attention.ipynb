{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63fd92bba910441d92e865b8b5c633d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_59ccea95a2744573a45bea17c4a9b974",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e559b5c82aa040359c37b4a4ae96f387",
              "IPY_MODEL_5b1a708273b2476eb34916ef1107efff"
            ]
          }
        },
        "59ccea95a2744573a45bea17c4a9b974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e559b5c82aa040359c37b4a4ae96f387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_1834868a9baf4deb955126192096ebd1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.07MB of 0.07MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c70dcd5c7324105add54fde95e7b2d6"
          }
        },
        "5b1a708273b2476eb34916ef1107efff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9746dfab641848a4864fa4c6fbc835af",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53f6ef739c064066b7a4cdf534e2b7dd"
          }
        },
        "1834868a9baf4deb955126192096ebd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c70dcd5c7324105add54fde95e7b2d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9746dfab641848a4864fa4c6fbc835af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53f6ef739c064066b7a4cdf534e2b7dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohithD5/CS6910_Assignment_3/blob/main/Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Di3vQ67MoB"
      },
      "source": [
        "src_url = \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\"\n",
        "src_zip = \"dakshina_dataset_v1.0.tar\"\n",
        "DATA_SRC=\"dakshina_dataset_v1.0/ta/lexicons\"\n",
        "DATA_TRAIN_SRC = \"/ta.translit.sampled.train.tsv\"\n",
        "DATA_VAL_SRC = \"/ta.translit.sampled.dev.tsv\" \n",
        "DATA_TEST_SRC = \"/ta.translit.sampled.test.tsv\"\n",
        "#TRAIN_IMAGES_PER_LABEL = 1000\n",
        "#TEST_IMAGES_PER_LABEL = 200\n",
        "BALANCED_SPLITS = {\"train\" : 900, \"val\" : 100}\n",
        "PROJECT_NAME = \"CS6910 ASSIGNMENT 3\"\n",
        "dataset='dakshina-dataset'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-65YGCSb7hED"
      },
      "source": [
        "%%capture\n",
        "!curl -SL $src_url > $src_zip\n",
        "!tar -xf $src_zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_jZdhj-LApj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "936873be-abf7-4e35-be0c-a7686a9ea1ef"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import shuffle\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, GRU, SimpleRNN, Dropout, Activation, dot, concatenate, TimeDistributed\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "from matplotlib.font_manager import FontProperties\n",
        "\n",
        "\n",
        "!pip3 install tensorflow -qqq\n",
        "!pip3 install wandb -qqq\n",
        "import wandb\n",
        "!wandb login\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs6910krsrd\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj4Bc_-Ynxgj"
      },
      "source": [
        "import matplotlib.font_manager as fm\n",
        "\n",
        "!wget https://github.com/arul20be/Latha-Tamil-Font/blob/master/system/fonts/NotoSansTamil-Regular.ttf\n",
        "fm.fontManager.ttflist += fm.createFontList(['NotoSansTamil-Regular.ttf'])\n",
        "plt.rc('font', family='NotoSansTamil-Regular-Regular')\n",
        "!mv NotoSansTamil-Regular.ttf /usr/share/fonts/truetype/liberation/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro8q3Xrgm_hi"
      },
      "source": [
        "!fc-list :lang=en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16PPx0aIOG2q"
      },
      "source": [
        "Uploading Data: only run once"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S3nODWoCSmF"
      },
      "source": [
        "\n",
        "run = wandb.init(project=PROJECT_NAME, entity='cs6910krsrd',job_type=\"upload\")\n",
        "\n",
        "# create an artifact for all the raw data\n",
        "raw_data_at = wandb.Artifact(dataset, type=\"raw_data\")\n",
        "\n",
        "raw_data_at.add_dir(DATA_SRC)\n",
        "\n",
        "# save artifact to W&B\n",
        "run.log_artifact(raw_data_at)\n",
        "run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMs_ZhWLOMbL"
      },
      "source": [
        "Downloading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMEcA_xBLk8o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274,
          "referenced_widgets": [
            "63fd92bba910441d92e865b8b5c633d4",
            "59ccea95a2744573a45bea17c4a9b974",
            "e559b5c82aa040359c37b4a4ae96f387",
            "5b1a708273b2476eb34916ef1107efff",
            "1834868a9baf4deb955126192096ebd1",
            "4c70dcd5c7324105add54fde95e7b2d6",
            "9746dfab641848a4864fa4c6fbc835af",
            "53f6ef739c064066b7a4cdf534e2b7dd"
          ]
        },
        "outputId": "4bfbf0c2-a78f-4ea9-c8ff-e6295adde149"
      },
      "source": [
        "run = wandb.init(project=PROJECT_NAME, entity='cs6910krsrd',job_type=\"download\")\n",
        "\n",
        "# Query W&B for an artifact and mark it as input to this run\n",
        "artifact = run.use_artifact(dataset+':latest')\n",
        "\n",
        "# Download the artifact's contents\n",
        "artifact_dir = artifact.download()\n",
        "run.finish()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs6910krsrd\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.30<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">fast-resonance-127</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/cs6910krsrd/CS6910%20ASSIGNMENT%203\" target=\"_blank\">https://wandb.ai/cs6910krsrd/CS6910%20ASSIGNMENT%203</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/cs6910krsrd/CS6910%20ASSIGNMENT%203/runs/35y0tjfz\" target=\"_blank\">https://wandb.ai/cs6910krsrd/CS6910%20ASSIGNMENT%203/runs/35y0tjfz</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210520_052726-35y0tjfz</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 385<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63fd92bba910441d92e865b8b5c633d4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.06MB of 0.06MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210520_052726-35y0tjfz/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210520_052726-35y0tjfz/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">fast-resonance-127</strong>: <a href=\"https://wandb.ai/cs6910krsrd/CS6910%20ASSIGNMENT%203/runs/35y0tjfz\" target=\"_blank\">https://wandb.ai/cs6910krsrd/CS6910%20ASSIGNMENT%203/runs/35y0tjfz</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQqVkbGjtI9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c92f8117-3a39-44b5-b745-148fc91a3fd4"
      },
      "source": [
        "MODEL_NAME = \"Seq2SeqAtt\"\n",
        "FINAL_MODEL_DIR = \"trained_model\"\n",
        "ENCODER=\"encoder\"\n",
        "DECODER=\"decoder\"\n",
        "\n",
        "\n",
        "colnames=[\"ntv\",\"rmn\",'nAtt'] #native, romanized and number of attestations\n",
        "df_train = pd.read_csv(artifact_dir + DATA_TRAIN_SRC,sep=\"\\t\",names=colnames,na_filter=False)\n",
        "df_val = pd.read_csv(artifact_dir + DATA_VAL_SRC,sep=\"\\t\",names=colnames,na_filter=False)\n",
        "MODEL_NAME = \"Seq2Seq\"\n",
        "FINAL_MODEL_DIR = \"trained_model\"\n",
        "\n",
        "\n",
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 20  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding and decoding space (LSTM/GRU/RNN)\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "embed_dim=16  #embedding size\n",
        "n_encoder=2 #number of encoder layers \n",
        "n_decoder=2 #number of decoder layers\n",
        "cell_type=\"LSTM\"#\"GRU\" \"RNN\" # Cell type of encoder and decoder\n",
        "do=0.2 #dropout\n",
        "beam_size=3\n",
        "\n",
        "input_texts = df_train.rmn.to_list()    # input words(romanized)\n",
        "target_texts = df_train.ntv.apply(lambda s:'\\t'+s+'\\n').to_list() # target words(native)\n",
        "input_characters = set(df_train.rmn.sum()) # input vocabulary (all english letters)\n",
        "target_characters = set(df_train.ntv.sum()) # target vocabulary (all tamil letters)\n",
        "val_input_texts = df_val.rmn.to_list()    # input words(romanized)\n",
        "val_target_texts = df_val.ntv.apply(lambda s: s).to_list() # target words(native)\n",
        "valid_target_texts = df_val.ntv.apply(lambda s:'\\t'+s+'\\n').to_list() # target words(native)\n",
        "\n",
        "\n",
        "input_characters = sorted(list(input_characters)) \n",
        "input_characters.append(' ')\n",
        "target_characters = sorted(list(target_characters))\n",
        "target_characters.append(' ')\n",
        "target_characters.append('\\t')\n",
        "target_characters.append('\\n')\n",
        "\n",
        "\n",
        "\n",
        "num_encoder_tokens = len(input_characters)   # size of input vocabulary\n",
        "num_decoder_tokens = len(target_characters)   # ize of target vocabulary\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])  # max input word size\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts]) # max output word size\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        " \n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)]) #dict mapping input letters to integers\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)]) #dict mapping output letters to integers\n",
        "\n",
        "encoder_input_data = np.zeros(                                              \n",
        "    (len(input_texts), max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "val_encoder_input_data = np.zeros(                                              \n",
        "    (len(val_input_texts), max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length,len(target_token_index)), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "val_decoder_input_data = np.zeros(\n",
        "    (len(val_input_texts), max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_decoder_target_data = np.zeros(\n",
        "    (len(val_input_texts), max_decoder_seq_length,len(target_token_index)), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "CELL={\"LSTM\":LSTM,\"GRU\":GRU,\"RNN\":SimpleRNN}\n",
        "\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 68218\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 49\n",
            "Max sequence length for inputs: 30\n",
            "Max sequence length for outputs: 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUWaPdROWtQ5"
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t] = input_token_index[char]\n",
        "    encoder_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t] =  target_token_index[char]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1,target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :] = target_token_index[\" \"]\n",
        "    decoder_target_data[i, t:,target_token_index[\" \"]] =  1.0\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(val_input_texts, valid_target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        val_encoder_input_data[i, t] = input_token_index[char]\n",
        "    val_encoder_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        val_decoder_input_data[i, t] =  target_token_index[char]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            val_decoder_target_data[i, t - 1,target_token_index[char]] = 1.0\n",
        "    val_decoder_input_data[i, t + 1 :] = target_token_index[\" \"]\n",
        "    val_decoder_target_data[i, t:,target_token_index[\" \"]] =  1.0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmqTQWJXbSQD",
        "outputId": "912e1f6f-5cee-4132-c5a9-c0b8b8e493fd"
      },
      "source": [
        "print(decode_sequence(encoder_input_data[20:21],3))\n",
        "print(input_texts[20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "போர்ஸ்\n",
            "\n",
            "force\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZk3KeveoOUe"
      },
      "source": [
        "Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nmy1VIBCOHk9"
      },
      "source": [
        "def train():\n",
        "\n",
        "  hyperparameter_defaults={\n",
        "    \"epochs\" : 10,\n",
        "    \"num_samples\" : 10000,\n",
        "    \"embed_dim\" : 64,\n",
        "    \"n_encoder\" : 1,\n",
        "    \"n_decoder\" : 1,\n",
        "    \"drop_out\" : 0.2,\n",
        "    'latent_dim':128,\n",
        "    'beam_size':0,\n",
        "    'batch_size':64,\n",
        "    'cell_type':\"LSTM\"\n",
        "    }\n",
        "\n",
        "  run = wandb.init(project=PROJECT_NAME, config=hyperparameter_defaults, entity='cs6910krsrd',job_type=\"train\")\n",
        "\n",
        "\n",
        "  cfg = wandb.config\n",
        "  batch_size = cfg.batch_size  # Batch size for training.\n",
        "  epochs = cfg.epochs  # Number of epochs to train for.\n",
        "  latent_dim = cfg.latent_dim  # Latent dimensionality of the encoding and decoding space (LSTM/GRU/RNN)\n",
        "  num_samples = cfg.num_samples  # Number of samples to train on.\n",
        "  embed_dim=cfg.embed_dim#embedding size\n",
        "  n_encoder=cfg.n_encoder #number of encoder layers \n",
        "  n_decoder=cfg.n_decoder #number of decoder layers\n",
        "  cell_type=cfg.cell_type#\"GRU\" \"RNN\" # Cell type of encoder and decoder\n",
        "  do=cfg.drop_out #dropout\n",
        "  beam_size=cfg.beam_size\n",
        "\n",
        "  encoder_inputs=Input(shape=(None,))\n",
        "  x = Embedding(num_encoder_tokens, embed_dim)(encoder_inputs)\n",
        "  encoder_states = []\n",
        "  x, state_h, state_c = CELL[cell_type](latent_dim,dropout=do,return_state=True,return_sequences=True)(x)\n",
        "  encoder= x #[x, state_h, state_c]\n",
        "  encoder_states = [state_h, state_c]\n",
        "\n",
        "  # Set up the decoder, using `encoder_states` as initial state.\n",
        "  decoder_inputs = Input(shape=(None,))\n",
        "  out_embed=Embedding(num_decoder_tokens, embed_dim)\n",
        "  embedded_word=out_embed(decoder_inputs)\n",
        "  x=embedded_word\n",
        "  output_layers = []\n",
        "  output_layers.append(\n",
        "        CELL[cell_type](latent_dim,dropout=do, return_sequences=True,return_state=True)\n",
        "  )\n",
        "  x,dh,dc = output_layers[-1](x, initial_state=encoder_states)\n",
        "  decoder= x#[x,dh,dc]\n",
        "\n",
        "  attention = dot([decoder, encoder], axes=[2, 2])\n",
        "  visualization=attention\n",
        "  attention = Activation('softmax')(visualization)\n",
        "  context = dot([attention, encoder], axes=[2,1])\n",
        "  decoder_combined_context = concatenate([context, decoder])\n",
        "\n",
        "  decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "  output=decoder_dense(decoder_combined_context)\n",
        "\n",
        "  \"\"\"#timedistributed?\n",
        "  decoder_dense1=TimeDistributed(Dense(latent_dim, activation=\"tanh\"))\n",
        "  decoder_dense2=TimeDistributed(Dense(num_decoder_tokens, activation=\"softmax\"))\n",
        "  output = decoder_dense1(decoder_combined_context)\n",
        "  output = decoder_dense2(output)\"\"\"\n",
        "\n",
        "  \"\"\"dropout = Dropout(rate=do)\n",
        "  x = dropout(x)\n",
        "  decoder_dense = Dense(num_decoder_tokens, activation='softmax')   #time_distributed?\n",
        "  decoder_outputs = decoder_dense(x)\"\"\"\n",
        "\n",
        "  # Define the model that will turn\n",
        "  # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "  model = Model([encoder_inputs, decoder_inputs], output)\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "  )\n",
        "  model.fit(\n",
        "      [encoder_input_data, decoder_input_data],\n",
        "      decoder_target_data,\n",
        "      batch_size=batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_split=0.2,\n",
        "  )\n",
        "\n",
        "  encoder_model = Model(encoder_inputs, [encoder,encoder_states])\n",
        "  #n_decoder=1\n",
        "\n",
        "  decoder_inputs = Input(shape=(None,))\n",
        "  embedded_word=out_embed(decoder_inputs)\n",
        "\n",
        "  decoder_states_inputs = []\n",
        "  decoder_states = []\n",
        "  d_outputs=embedded_word\n",
        "  current_state_inputs = [Input(shape=(latent_dim,)) for _ in range(2)]\n",
        "  encoder_outs=Input(shape=(None,latent_dim,))\n",
        "\n",
        "  temp = output_layers[0](d_outputs, initial_state=current_state_inputs)\n",
        "\n",
        "  d_outputs, cur_states = temp[0], temp[1:]\n",
        "  decoder_states += cur_states\n",
        "  decoder_states_inputs += current_state_inputs\n",
        "\n",
        "  attention_inf = dot([d_outputs, encoder_outs], axes=[2, 2])\n",
        "\n",
        "  attention_inf = Activation('softmax')(attention_inf)\n",
        "\n",
        "  visualization=attention_inf\n",
        "\n",
        "  context_inf = dot([attention_inf, encoder_outs], axes=[2,1])\n",
        "\n",
        "  decoder_combined_context_inf = concatenate([context_inf, d_outputs])\n",
        "\n",
        "  dec_output=decoder_dense(decoder_combined_context_inf)\n",
        "\n",
        "\n",
        "\n",
        "  decoder_model = Model(\n",
        "      [encoder_outs]+[decoder_inputs] + decoder_states_inputs,\n",
        "      [dec_output]+ [visualization] + decoder_states)\n",
        "\n",
        "\n",
        "\n",
        "  # Reverse-lookup token index to decode sequences back to\n",
        "  # something readable.\n",
        "  reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "  reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "  \n",
        "\n",
        "  trained_model_artifact = wandb.Artifact(\n",
        "            MODEL_NAME+\"trn\", type=\"model\",\n",
        "            description=\"trained model\",\n",
        "            metadata=dict(cfg))\n",
        "  \n",
        "  encoder_artifact = wandb.Artifact(\n",
        "            MODEL_NAME+\"enc\", type=\"model\",\n",
        "            description=\"encoder\",\n",
        "            metadata=dict(cfg))\n",
        "  \n",
        "  decoder_artifact = wandb.Artifact(\n",
        "            MODEL_NAME+\"dec\", type=\"model\",\n",
        "            description=\"decoder\",\n",
        "            metadata=dict(cfg))\n",
        "  \n",
        "  model.save(FINAL_MODEL_DIR)\n",
        "  encoder_model.save(ENCODER)\n",
        "  decoder_model.save(DECODER)\n",
        "\n",
        "  trained_model_artifact.add_dir(FINAL_MODEL_DIR)\n",
        "  encoder_artifact.add_dir(ENCODER)\n",
        "  decoder_artifact.add_dir(DECODER)\n",
        "\n",
        "\n",
        "  run.log_artifact(trained_model_artifact)\n",
        "  run.log_artifact(encoder_artifact)\n",
        "  run.log_artifact(decoder_artifact)\n",
        "  run.finish()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qthaEIZrPHa9"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2ONyb8qRyyI"
      },
      "source": [
        "def sigmoid(x):\n",
        "\tz = 1/(1 + np.exp(-x)) \n",
        "\treturn z\n",
        "\n",
        "def get_clr(value):\n",
        "\tcolors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8'\n",
        "\t\t'#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
        "\t\t'#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
        "\t\t'#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
        "\tvalue = int((value * 100) / 5)\n",
        "\treturn colors[value]\n",
        "\n",
        "# get html element\n",
        "def cstr(s, color='black'):\n",
        "\tif s == ' ':\n",
        "\t\treturn \"<text style=color:#000;padding-left:10px;background-color:{}> </text>\".format(color, s)\n",
        "\telse:\n",
        "\t\treturn \"<text style=color:#000;background-color:{}>{} </text>\".format(color, s)\n",
        "\t\n",
        "# print html\n",
        "def print_color(t):\n",
        "\tdisplay(html_print(''.join([cstr(ti, color=ci) for ti,ci in t])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UhSXd9ISuk4"
      },
      "source": [
        "def calcValAcc(encoder_model,decoder_model):\n",
        "  encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "  decoder_states_inputs = []\n",
        "  decoder_states = []\n",
        "  d_outputs=embedded_word\n",
        "  for j in range(n_decoder)[::-1]:\n",
        "    current_state_inputs = [Input(shape=(latent_dim,)) for _ in range(2)]\n",
        "\n",
        "    temp = output_layers[n_decoder-j-1](d_outputs, initial_state=current_state_inputs)\n",
        "\n",
        "    d_outputs, cur_states = temp[0], temp[1:]\n",
        "    decoder_states += cur_states\n",
        "    decoder_states_inputs += current_state_inputs\n",
        "\n",
        "  decoder_outputs = decoder_dense(d_outputs)\n",
        "  decoder_model = Model(\n",
        "      [decoder_inputs] + decoder_states_inputs,\n",
        "      [decoder_outputs] + decoder_states)\n",
        "\n",
        "  # Reverse-lookup token index to decode sequences back to\n",
        "  # something readable.\n",
        "  correct_pred=list()\n",
        "\n",
        "  for seq_index in range(len(val_encoder_input_data)):\n",
        "    input_seq = val_encoder_input_data[seq_index : seq_index + 1]\n",
        "    pred=decode_sequence(input_seq, beam_size,encoder_model,decoder_model)\n",
        "    #print(input_seq,\"pred:\",pred,\"true\",val_target_texts[seq_index:seq_index+1])\n",
        "    #print(\"yay\",pred,val_target_texts[seq_index])\n",
        "    if pred==val_target_texts[seq_index:seq_index+1]:\n",
        "      correct_pred.append(1)\n",
        "      #print(\"correctpred\")\n",
        "    else:\n",
        "      correct_pred.append(0)\n",
        "    \n",
        "  val_accuracy=np.mean(np.array(correct_pred))\n",
        "\n",
        "  print(val_accuracy)\n",
        "  return(val_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy9XolOlUBqj"
      },
      "source": [
        "def calcValAcc(encoder_model,decoder_model):\n",
        "  encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "  decoder_states_inputs = []\n",
        "  decoder_states = []\n",
        "  d_outputs=embedded_word\n",
        "  for j in range(n_decoder)[::-1]:\n",
        "    current_state_inputs = [Input(shape=(latent_dim,)) for _ in range(2)]\n",
        "\n",
        "    temp = output_layers[n_decoder-j-1](d_outputs, initial_state=current_state_inputs)\n",
        "\n",
        "    d_outputs, cur_states = temp[0], temp[1:]\n",
        "    decoder_states += cur_states\n",
        "    decoder_states_inputs += current_state_inputs\n",
        "\n",
        "  decoder_outputs = decoder_dense(d_outputs)\n",
        "  decoder_model = Model(\n",
        "      [decoder_inputs] + decoder_states_inputs,\n",
        "      [decoder_outputs] + decoder_states)\n",
        "\n",
        "  # Reverse-lookup token index to decode sequences back to\n",
        "  # something readable.\n",
        "  correct_pred=list()\n",
        "\n",
        "  for seq_index in range(len(val_encoder_input_data)):\n",
        "    input_seq = val_encoder_input_data[seq_index : seq_index + 1]\n",
        "    pred=decode_sequence(input_seq, beam_size,encoder_model,decoder_model)\n",
        "    #print(input_seq,\"pred:\",pred,\"true\",val_target_texts[seq_index:seq_index+1])\n",
        "    #print(\"yay\",pred,val_target_texts[seq_index])\n",
        "    if pred==val_target_texts[seq_index:seq_index+1]:\n",
        "      correct_pred.append(1)\n",
        "      #print(\"correctpred\")\n",
        "    else:\n",
        "      correct_pred.append(0)\n",
        "    \n",
        "  val_accuracy=np.mean(np.array(correct_pred))\n",
        "\n",
        "  print(val_accuracy)\n",
        "  return(val_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdRG69tVPAlo"
      },
      "source": [
        "run = wandb.init(project=PROJECT_NAME, job_type=\"inference\")\n",
        "enc_model_at = run.use_artifact('cs6910krsrd/CS6910 ASSIGNMENT 3/Seq2Seqenc:v1', type='model')\n",
        "model_dir= enc_model_at.download()\n",
        "encoder_model=tf.keras.models.load_model(model_dir)\n",
        "dec_model_at = run.use_artifact('cs6910krsrd/CS6910 ASSIGNMENT 3/Seq2Seqdec:v1', type='model')\n",
        "model_dir= dec_model_at.download()\n",
        "decoder_model=tf.keras.models.load_model(model_dir)\n",
        "\n",
        "run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh2w2Bd1mVC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "231adb5d-0952-4079-db74-b7df79e27314"
      },
      "source": [
        "encoder_inputs=Input(shape=(None,))\n",
        "x = Embedding(num_encoder_tokens, embed_dim)(encoder_inputs)\n",
        "encoder_states = []\n",
        "x, state_h, state_c = CELL[cell_type](latent_dim,dropout=do,return_state=True,return_sequences=True)(x)\n",
        "encoder= x #[x, state_h, state_c]\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "out_embed=Embedding(num_decoder_tokens, embed_dim)\n",
        "embedded_word=out_embed(decoder_inputs)\n",
        "x=embedded_word\n",
        "output_layers = []\n",
        "output_layers.append(\n",
        "      CELL[cell_type](latent_dim,dropout=do, return_sequences=True,return_state=True)\n",
        ")\n",
        "x,dh,dc = output_layers[-1](x, initial_state=encoder_states)\n",
        "decoder= x#[x,dh,dc]\n",
        "\n",
        "attention = dot([decoder, encoder], axes=[2, 2])\n",
        "visualization=attention\n",
        "attention = Activation('softmax')(visualization)\n",
        "context = dot([attention, encoder], axes=[2,1])\n",
        "decoder_combined_context = concatenate([context, decoder])\n",
        "\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "output=decoder_dense(decoder_combined_context)\n",
        "\n",
        "\"\"\"#timedistributed?\n",
        "decoder_dense1=TimeDistributed(Dense(latent_dim, activation=\"tanh\"))\n",
        "decoder_dense2=TimeDistributed(Dense(num_decoder_tokens, activation=\"softmax\"))\n",
        "output = decoder_dense1(decoder_combined_context)\n",
        "output = decoder_dense2(output)\"\"\"\n",
        "\n",
        "\"\"\"dropout = Dropout(rate=do)\n",
        "x = dropout(x)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')   #time_distributed?\n",
        "decoder_outputs = decoder_dense(x)\"\"\"\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "\n",
        "# Define sampling models\n",
        "# Restore the model and construct the encoder and decoder.\n",
        "model = keras.models.load_model(\"s2s_tamil\")\n",
        "\n",
        "  encoder_model = Model(encoder_inputs, [encoder,encoder_states])\n",
        "  #n_decoder=1\n",
        "\n",
        "  decoder_inputs = Input(shape=(None,))\n",
        "  embedded_word=out_embed(decoder_inputs)\n",
        "\n",
        "  decoder_states_inputs = []\n",
        "  decoder_states = []\n",
        "  d_outputs=embedded_word\n",
        "  current_state_inputs = [Input(shape=(latent_dim,)) for _ in range(2)]\n",
        "  encoder_outs=Input(shape=(None,latent_dim,))\n",
        "\n",
        "  temp = output_layers[0](d_outputs, initial_state=current_state_inputs)\n",
        "\n",
        "  d_outputs, cur_states = temp[0], temp[1:]\n",
        "  decoder_states += cur_states\n",
        "  decoder_states_inputs += current_state_inputs\n",
        "\n",
        "  attention_inf = dot([d_outputs, encoder_outs], axes=[2, 2])\n",
        "\n",
        "  attention_inf = Activation('softmax')(attention_inf)\n",
        "\n",
        "  visualization=attention_inf\n",
        "\n",
        "  context_inf = dot([attention_inf, encoder_outs], axes=[2,1])\n",
        "\n",
        "  decoder_combined_context_inf = concatenate([context_inf, d_outputs])\n",
        "\n",
        "  dec_output=decoder_dense(decoder_combined_context_inf)\n",
        "\n",
        "\n",
        "\n",
        "  decoder_model = Model(\n",
        "      [encoder_outs]+[decoder_inputs] + decoder_states_inputs,\n",
        "      [dec_output]+ [visualization] + decoder_states)\n",
        "\n",
        "\n",
        "\n",
        "  # Reverse-lookup token index to decode sequences back to\n",
        "  # something readable.\n",
        "  reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "  reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "\n",
        "# Save model\n",
        "model.save(\"s2s_tamil\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "853/853 [==============================] - 13s 12ms/step - loss: 1.1034 - accuracy: 0.7137 - val_loss: 0.8015 - val_accuracy: 0.7969\n",
            "Epoch 2/20\n",
            "853/853 [==============================] - 9s 11ms/step - loss: 0.5164 - accuracy: 0.8472 - val_loss: 0.5569 - val_accuracy: 0.8754\n",
            "Epoch 3/20\n",
            "853/853 [==============================] - 9s 11ms/step - loss: 0.2679 - accuracy: 0.9265 - val_loss: 0.4260 - val_accuracy: 0.9087\n",
            "Epoch 4/20\n",
            "853/853 [==============================] - 10s 11ms/step - loss: 0.1537 - accuracy: 0.9590 - val_loss: 0.3882 - val_accuracy: 0.9171\n",
            "Epoch 5/20\n",
            "853/853 [==============================] - 10s 11ms/step - loss: 0.1138 - accuracy: 0.9692 - val_loss: 0.3984 - val_accuracy: 0.9144\n",
            "Epoch 6/20\n",
            "853/853 [==============================] - 9s 11ms/step - loss: 0.0918 - accuracy: 0.9748 - val_loss: 0.4404 - val_accuracy: 0.9031\n",
            "Epoch 7/20\n",
            "853/853 [==============================] - 9s 11ms/step - loss: 0.0786 - accuracy: 0.9780 - val_loss: 0.4795 - val_accuracy: 0.8989\n",
            "Epoch 8/20\n",
            "853/853 [==============================] - 10s 11ms/step - loss: 0.0684 - accuracy: 0.9808 - val_loss: 0.4452 - val_accuracy: 0.9106\n",
            "Epoch 9/20\n",
            "853/853 [==============================] - 9s 11ms/step - loss: 0.0605 - accuracy: 0.9831 - val_loss: 0.4807 - val_accuracy: 0.9008\n",
            "Epoch 10/20\n",
            "853/853 [==============================] - 9s 11ms/step - loss: 0.0531 - accuracy: 0.9852 - val_loss: 0.4662 - val_accuracy: 0.9088\n",
            "Epoch 11/20\n",
            "853/853 [==============================] - 9s 11ms/step - loss: 0.0477 - accuracy: 0.9867 - val_loss: 0.5096 - val_accuracy: 0.8999\n",
            "Epoch 12/20\n",
            "853/853 [==============================] - 9s 11ms/step - loss: 0.0418 - accuracy: 0.9882 - val_loss: 0.5099 - val_accuracy: 0.9016\n",
            "Epoch 13/20\n",
            "853/853 [==============================] - 10s 11ms/step - loss: 0.0387 - accuracy: 0.9892 - val_loss: 0.5212 - val_accuracy: 0.9015\n",
            "Epoch 14/20\n",
            "853/853 [==============================] - 10s 11ms/step - loss: 0.0350 - accuracy: 0.9901 - val_loss: 0.5701 - val_accuracy: 0.8913\n",
            "Epoch 15/20\n",
            "853/853 [==============================] - 9s 11ms/step - loss: 0.0325 - accuracy: 0.9908 - val_loss: 0.5477 - val_accuracy: 0.8989\n",
            "Epoch 16/20\n",
            "853/853 [==============================] - 9s 11ms/step - loss: 0.0291 - accuracy: 0.9918 - val_loss: 0.5589 - val_accuracy: 0.8990\n",
            "Epoch 17/20\n",
            "853/853 [==============================] - 9s 11ms/step - loss: 0.0274 - accuracy: 0.9921 - val_loss: 0.5613 - val_accuracy: 0.9004\n",
            "Epoch 18/20\n",
            "853/853 [==============================] - 9s 11ms/step - loss: 0.0255 - accuracy: 0.9927 - val_loss: 0.6003 - val_accuracy: 0.8955\n",
            "Epoch 19/20\n",
            "853/853 [==============================] - 9s 11ms/step - loss: 0.0235 - accuracy: 0.9932 - val_loss: 0.5914 - val_accuracy: 0.8967\n",
            "Epoch 20/20\n",
            "853/853 [==============================] - 10s 11ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.5899 - val_accuracy: 0.9020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_42_layer_call_and_return_conditional_losses, lstm_cell_42_layer_call_fn, lstm_cell_43_layer_call_and_return_conditional_losses, lstm_cell_43_layer_call_fn, lstm_cell_42_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_42_layer_call_and_return_conditional_losses, lstm_cell_42_layer_call_fn, lstm_cell_43_layer_call_and_return_conditional_losses, lstm_cell_43_layer_call_fn, lstm_cell_42_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: s2s_tamil/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: s2s_tamil/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqG4kyXuprgF"
      },
      "source": [
        "# Define sampling models\n",
        "# Restore the model and construct the encoder and decoder.\n",
        "model = keras.models.load_model(\"s2s_tamil\")\n",
        "\n",
        "encoder_model = Model(encoder_inputs, [encoder,encoder_states])\n",
        "#n_decoder=1\n",
        "\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "embedded_word=out_embed(decoder_inputs)\n",
        "\n",
        "decoder_states_inputs = []\n",
        "decoder_states = []\n",
        "d_outputs=embedded_word\n",
        "current_state_inputs = [Input(shape=(latent_dim,)) for _ in range(2)]\n",
        "encoder_outs=Input(shape=(None,latent_dim,))\n",
        "\n",
        "temp = output_layers[0](d_outputs, initial_state=current_state_inputs)\n",
        "\n",
        "d_outputs, cur_states = temp[0], temp[1:]\n",
        "decoder_states += cur_states\n",
        "decoder_states_inputs += current_state_inputs\n",
        "\n",
        "attention_inf = dot([d_outputs, encoder_outs], axes=[2, 2])\n",
        "\n",
        "attention_inf = Activation('softmax')(attention_inf)\n",
        "\n",
        "visualization=attention_inf\n",
        "\n",
        "context_inf = dot([attention_inf, encoder_outs], axes=[2,1])\n",
        "\n",
        "decoder_combined_context_inf = concatenate([context_inf, d_outputs])\n",
        "\n",
        "dec_output=decoder_dense(decoder_combined_context_inf)\n",
        "\n",
        "\n",
        "\n",
        "decoder_model = Model(\n",
        "    [encoder_outs]+[decoder_inputs] + decoder_states_inputs,\n",
        "    [dec_output]+ [visualization] + decoder_states)\n",
        "\n",
        "\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l0Fzs29S_BJ"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    temp= (encoder_model.predict(input_seq))\n",
        "\n",
        "    e_out=temp[0]\n",
        "\n",
        "    states_value=temp[1:]\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index[\"\\t\"]\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    vis_list=list()\n",
        "    end_char_ind=np.max(input_seq[0])\n",
        "    for i in range(len(input_seq[0])):\n",
        "      if input_seq[0][i] == end_char_ind:\n",
        "        break\n",
        "\n",
        "    while not stop_condition:\n",
        "        #print(\"a\",np.shape([target_seq] + states_value))\n",
        "        output_tokens, visualization, h, c = decoder_model.predict([e_out]+[target_seq] + states_value)\n",
        "\n",
        "\n",
        "        vis_list.append(visualization[0][0][:i+1])\n",
        "\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    n_dots=np.array(np.shape(vis_list))\n",
        "    print(n_dots*10)\n",
        "    mat=np.zeros(n_dots*10)\n",
        "\n",
        "    print(np.shape(mat))\n",
        "    xt=list()\n",
        "    yt=list()\n",
        "\n",
        "    if plot=True\n",
        "    fig, ax = plt.subplots()\n",
        "    for i,vis in enumerate(vis_list):\n",
        "      for j, color in enumerate(vis):\n",
        "        mat[i*10:i*10+10,j*10:j*10+10]=color\n",
        "        yt.append(j*10+5)\n",
        "        xt.append(i*10+5)\n",
        "        \n",
        "    \n",
        "    ax.imshow(mat)\n",
        "    ax.set_xticks(yt)\n",
        "    ax.set_yticks(xt)\n",
        "\n",
        "    print([reverse_input_char_index[token] for token in input_seq[0][:i]])\n",
        "\n",
        "    ax.set_xticklabels([reverse_input_char_index[token] for token in input_seq[0][:i]])\n",
        "    ax.set_yticklabels(decoded_sentence)\n",
        "\n",
        "\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISOUJWT6UWrx"
      },
      "source": [
        "def connectivity(input_seq,beam_size,plot=False):\n",
        "    # Encode the input as state vectors.\n",
        "    temp= (encoder_model.predict(input_seq))\n",
        "\n",
        "    k=beam_size\n",
        "\n",
        "    e_out=temp[0]\n",
        "\n",
        "    states_value=temp[1:]\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index[\"\\t\"]\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    vis_list=list()\n",
        "    end_char_ind=np.max(input_seq[0])\n",
        "    for in_size in range(len(input_seq[0])):\n",
        "      if input_seq[0][in_size] == end_char_ind:\n",
        "        break\n",
        "\n",
        "    end_index=target_token_index[\"\\n\"] #sample index to check for end\n",
        "\n",
        "\n",
        "\n",
        "    sequences=[[list(),0.0,states_value,False,list()]]\n",
        "\n",
        "    while not stop_condition:\n",
        "\n",
        "        \n",
        "        new_sequences=list()\n",
        "        stop_condition=True\n",
        "        #print(\"a\",np.shape([target_seq] + states_value)) \n",
        "        #print(\"a\",np.shape([target_seq] + states_value))\n",
        "        for i in range(len(sequences)):\n",
        "          seq, score, states_value,stop_seq, vis_list = sequences[i].copy()\n",
        "\n",
        "          if stop_seq:\n",
        "            new_sequences.append(sequences[i])\n",
        "\n",
        "          else:\n",
        "            stop_condition=False                                         #if atleast one sequence is unfinished, decoding must continue\n",
        "            if len(seq)!=0:                                              #dont run for first iteration\n",
        "              sampled_token_index=seq[-1]\n",
        "              target_seq = np.zeros((1, 1))\n",
        "              target_seq[0, 0] = sampled_token_index\n",
        "              \n",
        "            output_tokens, visualization, h, c = decoder_model.predict([e_out]+[target_seq] + states_value)\n",
        "            v=vis_list.copy()\n",
        "            v.append(visualization[0][0][:in_size+1])\n",
        "\n",
        "            output_tokens=output_tokens[0, -1, :]\n",
        "            new_states_value=[h,c]\n",
        "\n",
        "\n",
        "            for j in range(len(output_tokens)):\n",
        "              if j == end_index or len(seq) > max_decoder_seq_length:\n",
        "                new_seq = [seq + [j], score - np.log(output_tokens[j]),new_states_value,True,v]\n",
        "              else:\n",
        "                new_seq = [seq + [j], score - np.log(output_tokens[j]),new_states_value,False,v]\n",
        "              new_sequences.append(new_seq)\n",
        "\n",
        "        ordered = sorted(new_sequences, key=lambda tup:tup[1])\n",
        "\n",
        "        sequences = ordered[:k]\n",
        "        print(np.shape(sequences[0][-1]))\n",
        "\n",
        "\n",
        "    best_seq=sequences[0][0]\n",
        "    for sampled_token_index in best_seq:\n",
        "      sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "      decoded_sentence += sampled_char\n",
        "\n",
        "    #print(sequences[0])\n",
        "\n",
        "    vis_list=sequences[0][-1]\n",
        "    n_dots=np.array(np.shape(vis_list))\n",
        "    print(n_dots*10)\n",
        "    mat=np.zeros(n_dots*10)\n",
        "    #print(vis_list)\n",
        "    print(np.shape(mat))\n",
        "    xt=list()\n",
        "    yt=list()\n",
        "\n",
        "    if plot==True:\n",
        "      fig, ax = plt.subplots()\n",
        "      for i,vis in enumerate(vis_list):\n",
        "        yt=list()\n",
        "        for j, color in enumerate(vis):\n",
        "          mat[i*10:i*10+10,j*10:j*10+10]=color\n",
        "          yt.append(j*10+5)\n",
        "        xt.append(i*10+5)\n",
        "\n",
        "      print(xt)\n",
        "          \n",
        "      \n",
        "      ax.imshow(mat)\n",
        "      ax.set_xticks(yt)\n",
        "      ax.set_yticks(xt)\n",
        "\n",
        "      ax.set_xticklabels(list([reverse_input_char_index[token] for token in input_seq[0][:i]]))\n",
        "      ax.set_yticklabels(best_seq)\n",
        "      fontproperties=FontProperties(fname=\"fonts/Catamaran-Light.ttf\")\n",
        "\n",
        "      print(best_seq)\n",
        "      \n",
        "\n",
        "\n",
        "    \n",
        "      plt.show()\n",
        "\n",
        "\n",
        "    return (decoded_sentence,vis_list)"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t6YT2Igpj75o",
        "outputId": "2c675ffc-a68d-4c5b-a6e6-29a38703f721"
      },
      "source": [
        "res, vis=connectivity(val_encoder_input_data[10:11],3,True)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.5640503e-12 5.9979907e-14 1.1153970e-13 2.5718112e-16 1.5900840e-16\n",
            " 2.1817437e-16 2.0342529e-16 2.1156110e-16 1.7764053e-17 1.9721919e-16\n",
            " 1.2869725e-16 5.1608464e-18 1.6746781e-16]\n",
            "(1, 13)\n",
            "[1.2287646e-06 2.8592896e-07 2.7427620e-07 1.2355887e-09 5.3534810e-10\n",
            " 2.7489375e-10 7.2838796e-10 4.5467630e-09 2.3723373e-10 8.7151525e-10\n",
            " 2.6312990e-09 1.9118776e-10 3.6650756e-09]\n",
            "[4.8709671e-06 5.9778569e-07 5.9092213e-07 9.7830206e-09 5.2733973e-09\n",
            " 3.3348531e-09 9.7176311e-09 1.5217324e-07 9.4047037e-09 4.3634344e-08\n",
            " 2.3847309e-07 9.9222879e-09 1.9735884e-07]\n",
            "[1.1098623e-04 4.4745661e-06 1.4161812e-05 2.3137437e-07 3.4455532e-08\n",
            " 2.9154595e-08 3.6721541e-08 3.9924868e-07 9.1421313e-08 3.1458123e-07\n",
            " 1.1359780e-06 5.5336361e-08 5.2048813e-07]\n",
            "(2, 13)\n",
            "[1.4676311e-04 4.9110959e-06 5.9219896e-05 3.6434824e-06 1.1618446e-06\n",
            " 1.3275719e-06 1.6630154e-06 8.3134953e-05 3.6012129e-06 5.3424905e-05\n",
            " 8.9749967e-04 2.7945340e-05 8.5939461e-04]\n",
            "[4.20165947e-04 1.50031265e-05 1.69190651e-04 7.39113466e-06\n",
            " 2.85142823e-06 6.82374275e-06 9.12846917e-06 3.50525224e-04\n",
            " 2.20244983e-05 1.56545619e-04 3.29396944e-03 1.40580014e-04\n",
            " 5.70465717e-03]\n",
            "[1.6629590e-04 5.2887267e-06 1.7400664e-04 6.6937946e-06 1.5441016e-06\n",
            " 1.6269815e-06 1.1360588e-06 1.8080995e-04 1.2476624e-05 4.9010321e-04\n",
            " 8.7762428e-03 9.6371841e-05 9.4036171e-03]\n",
            "(3, 13)\n",
            "[1.3924128e-04 3.7361390e-06 2.9859380e-04 1.0539969e-05 4.9054356e-06\n",
            " 3.9406023e-06 9.4824672e-06 5.6492438e-04 4.1820098e-05 2.6545471e-03\n",
            " 1.4494491e-01 4.5870072e-03 2.9872844e-02]\n",
            "[1.4087620e-04 7.3520882e-06 1.3000867e-04 2.9137211e-06 1.9691952e-05\n",
            " 8.6466989e-06 1.9391206e-05 2.9990767e-04 2.7611841e-05 1.0691071e-04\n",
            " 3.3152211e-04 4.7717171e-05 3.8989456e-04]\n",
            "[4.4832963e-05 1.4804693e-06 9.1447640e-05 2.1926876e-06 1.2114854e-06\n",
            " 2.0305924e-06 4.9602495e-06 1.4845880e-04 1.9786125e-05 6.1543711e-04\n",
            " 3.3867642e-02 9.2354085e-04 2.0631237e-02]\n",
            "(4, 13)\n",
            "[4.0245820e-07 5.9523241e-08 5.4036622e-07 2.8512768e-09 1.0024284e-07\n",
            " 2.2753815e-07 1.3958542e-06 8.6292202e-06 1.7502557e-06 2.6316240e-05\n",
            " 9.5076750e-05 6.9523126e-06 3.4039931e-05]\n",
            "[1.4998397e-05 5.2905790e-07 1.1446504e-05 2.0689408e-06 2.5172692e-05\n",
            " 9.8396222e-06 5.5442993e-05 4.0625334e-03 1.8106795e-04 2.4989808e-03\n",
            " 1.4791591e-01 2.6135051e-03 6.0970873e-02]\n",
            "[2.9703321e-07 1.6763046e-08 1.4760958e-07 4.0937545e-10 2.2240576e-08\n",
            " 9.4812471e-08 7.6717913e-07 4.6489872e-06 1.0875078e-06 1.1557857e-05\n",
            " 4.3512868e-05 1.3596494e-06 3.6381058e-05]\n",
            "(5, 13)\n",
            "[2.6489596e-04 1.5275149e-05 7.3598640e-05 2.0183236e-06 5.7828976e-07\n",
            " 1.0079956e-06 2.9741459e-06 8.4093655e-05 2.1196003e-05 1.7427236e-03\n",
            " 1.6072732e-01 1.5746801e-03 1.8608376e-02]\n",
            "[1.5587213e-07 8.1917293e-08 3.5420499e-07 9.2902788e-09 1.8350485e-07\n",
            " 1.2451457e-07 2.4564446e-07 2.3808554e-06 1.2584938e-07 2.7542678e-06\n",
            " 1.5009617e-05 2.4346937e-07 1.2977254e-06]\n",
            "[3.4566861e-04 1.3029698e-05 7.8520257e-05 1.2157604e-06 4.2761090e-07\n",
            " 1.1167909e-06 3.2585867e-06 6.3357678e-05 1.4059029e-05 1.4295621e-03\n",
            " 2.1028088e-01 1.6510141e-03 1.7500769e-02]\n",
            "(6, 13)\n",
            "[2.0196193e-04 6.5796470e-05 3.7401318e-05 2.4453025e-06 1.3323055e-04\n",
            " 1.3195192e-04 1.8257071e-03 1.0135131e-03 8.6692598e-04 1.6444862e-03\n",
            " 4.6494566e-03 2.1887433e-03 3.2773794e-04]\n",
            "[1.7231167e-04 4.1337295e-05 3.0733536e-05 9.6190752e-07 6.8939356e-05\n",
            " 7.8309851e-05 1.1979042e-03 4.5670939e-04 3.9318638e-04 7.8482518e-04\n",
            " 3.5311226e-03 1.5997628e-03 6.8006001e-04]\n",
            "[7.2898333e-06 5.0648055e-07 7.5054913e-07 2.3012173e-07 2.3784381e-07\n",
            " 2.9463436e-07 8.2897446e-07 3.4063611e-05 9.9056660e-06 2.3352563e-04\n",
            " 1.8026061e-02 7.3402707e-04 9.4385603e-03]\n",
            "(7, 13)\n",
            "[4.9730187e-04 1.4264522e-04 8.6243796e-05 9.6116764e-06 2.4341034e-05\n",
            " 5.2603515e-05 3.0370490e-04 1.0670285e-03 3.3196926e-04 1.6841002e-02\n",
            " 3.2112616e-01 1.7068239e-03 7.7132747e-02]\n",
            "[7.6492294e-04 1.6811317e-04 1.6400975e-04 9.5654223e-06 2.1995445e-05\n",
            " 4.9058708e-05 2.5909397e-04 7.1747991e-04 1.1876754e-04 8.5665127e-03\n",
            " 2.4274522e-01 1.0115749e-03 7.2223678e-02]\n",
            "[2.8151662e-06 4.7061988e-07 1.0014520e-06 7.6230172e-08 1.5269025e-06\n",
            " 1.3280401e-06 3.7283403e-06 4.3931263e-06 1.0420218e-06 1.6756674e-05\n",
            " 6.0425216e-05 8.0699027e-07 8.8471570e-06]\n",
            "(8, 13)\n",
            "[3.12642485e-04 4.72960179e-04 6.66909837e-05 1.13527167e-05\n",
            " 4.53620851e-05 1.55077738e-04 2.57809705e-04 1.35036433e-04\n",
            " 1.65306250e-04 1.28267595e-04 1.19397315e-04 4.92151730e-06\n",
            " 6.17052056e-03]\n",
            "[1.6395340e-06 6.3955565e-07 1.1970648e-07 1.0021851e-08 7.4649044e-08\n",
            " 9.9743048e-08 4.0174680e-07 5.0801560e-08 6.8686084e-08 3.8544161e-07\n",
            " 9.6236690e-08 2.5361881e-09 1.5069054e-07]\n",
            "[3.3229034e-04 2.5745416e-05 1.2962371e-05 1.4103791e-06 8.4030495e-07\n",
            " 2.8922493e-06 4.0827840e-06 6.4122665e-05 2.2670229e-05 1.0935689e-03\n",
            " 3.5508487e-02 2.3823972e-04 1.2761586e-02]\n",
            "(9, 13)\n",
            "[1.0568965e-05 4.0915969e-05 3.3385728e-05 4.0254323e-05 1.1049378e-04\n",
            " 9.5484327e-05 1.5161109e-04 4.6118526e-04 6.1874470e-04 1.1295367e-03\n",
            " 1.0435020e-03 1.0632935e-04 5.0253695e-01]\n",
            "[9.8367757e-04 2.6115396e-03 1.0190116e-03 5.6545687e-05 1.2260526e-04\n",
            " 1.4264173e-04 2.4215906e-04 1.0653455e-03 3.3522808e-04 4.9845199e-03\n",
            " 2.1605068e-03 1.4948489e-05 9.0073338e-03]\n",
            "[1.55494155e-04 7.31181935e-05 7.49112360e-06 2.98012378e-06\n",
            " 9.48312882e-05 1.20643075e-04 5.14356827e-04 6.74693147e-05\n",
            " 1.77395807e-04 3.33656877e-04 4.24400205e-04 2.41139598e-04\n",
            " 2.18718211e-04]\n",
            "(10, 13)\n",
            "[5.3977292e-06 5.6641700e-05 3.5501933e-05 7.9875354e-06 5.7576985e-05\n",
            " 4.7789883e-05 4.7835394e-05 4.6674531e-06 1.4535089e-05 1.6530948e-05\n",
            " 3.3887261e-07 1.1100651e-07 1.8212924e-05]\n",
            "[2.30350065e-06 1.52242865e-05 1.87590717e-06 8.02207296e-07\n",
            " 1.48328695e-06 8.89106502e-07 1.12565533e-06 8.38638414e-07\n",
            " 8.27439237e-07 4.21161332e-07 1.86116580e-07 3.71016817e-08\n",
            " 1.59516683e-04]\n",
            "[1.6205601e-03 1.3397017e-03 1.2998865e-04 3.8250651e-05 3.8661718e-04\n",
            " 7.7894557e-04 2.4811041e-03 5.6773494e-03 3.7607709e-03 2.9863127e-02\n",
            " 5.7525568e-02 2.1473744e-03 1.1677565e-01]\n",
            "(11, 13)\n",
            "[2.1582300e-05 4.9156071e-05 7.7461198e-05 1.0361965e-04 6.1611565e-05\n",
            " 6.6167035e-05 7.7803539e-05 1.7305222e-04 1.7556346e-04 4.6154129e-04\n",
            " 3.7193752e-04 1.2844639e-04 2.0777334e-01]\n",
            "[1.3227937e-04 2.3502586e-04 7.4239717e-05 1.9121311e-04 3.7297588e-05\n",
            " 8.2051367e-05 5.0408802e-05 2.3202205e-04 3.3714029e-04 7.1646820e-04\n",
            " 5.7913869e-04 5.9746322e-05 4.0025276e-01]\n",
            "(11, 13)\n",
            "[3.7374430e-05 1.6526306e-04 3.0576106e-04 5.3691983e-05 1.2455929e-04\n",
            " 1.3579242e-04 1.1346687e-04 2.3032712e-06 1.7136248e-05 4.8629088e-05\n",
            " 1.0547921e-06 6.4227930e-07 4.1486666e-05]\n",
            "[1.5292896e-06 2.3913584e-05 5.0047829e-06 1.9949766e-06 2.8406235e-05\n",
            " 9.8647570e-06 1.2574190e-05 3.7553741e-07 7.5633197e-06 3.7958359e-06\n",
            " 4.8987179e-08 8.3951612e-08 6.0643874e-06]\n",
            "(11, 13)\n",
            "(11, 13)\n",
            "[110 130]\n",
            "(110, 130)\n",
            "[5, 15, 25, 35, 45, 55, 65, 75, 85, 95, 105]\n",
            "[1, 12, 26, 45, 26, 35, 21, 34, 25, 45, 48]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7QrTcDrvMkN",
        "outputId": "a935bbdb-7164-42ab-b37e-af5fdbbb22f0"
      },
      "source": [
        "vis"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.5640503e-12, 5.9979907e-14, 1.1153970e-13, 2.5718112e-16,\n",
              "        1.5900840e-16, 2.1817437e-16, 2.0342529e-16, 2.1156110e-16,\n",
              "        1.7764053e-17, 1.9721919e-16, 1.2869725e-16, 5.1608464e-18,\n",
              "        1.6746781e-16], dtype=float32),\n",
              " array([1.2287646e-06, 2.8592896e-07, 2.7427620e-07, 1.2355887e-09,\n",
              "        5.3534810e-10, 2.7489375e-10, 7.2838796e-10, 4.5467630e-09,\n",
              "        2.3723373e-10, 8.7151525e-10, 2.6312990e-09, 1.9118776e-10,\n",
              "        3.6650756e-09], dtype=float32),\n",
              " array([1.4676311e-04, 4.9110959e-06, 5.9219896e-05, 3.6434824e-06,\n",
              "        1.1618446e-06, 1.3275719e-06, 1.6630154e-06, 8.3134953e-05,\n",
              "        3.6012129e-06, 5.3424905e-05, 8.9749967e-04, 2.7945340e-05,\n",
              "        8.5939461e-04], dtype=float32),\n",
              " array([1.3924128e-04, 3.7361390e-06, 2.9859380e-04, 1.0539969e-05,\n",
              "        4.9054356e-06, 3.9406023e-06, 9.4824672e-06, 5.6492438e-04,\n",
              "        4.1820098e-05, 2.6545471e-03, 1.4494491e-01, 4.5870072e-03,\n",
              "        2.9872844e-02], dtype=float32),\n",
              " array([4.0245820e-07, 5.9523241e-08, 5.4036622e-07, 2.8512768e-09,\n",
              "        1.0024284e-07, 2.2753815e-07, 1.3958542e-06, 8.6292202e-06,\n",
              "        1.7502557e-06, 2.6316240e-05, 9.5076750e-05, 6.9523126e-06,\n",
              "        3.4039931e-05], dtype=float32),\n",
              " array([2.6489596e-04, 1.5275149e-05, 7.3598640e-05, 2.0183236e-06,\n",
              "        5.7828976e-07, 1.0079956e-06, 2.9741459e-06, 8.4093655e-05,\n",
              "        2.1196003e-05, 1.7427236e-03, 1.6072732e-01, 1.5746801e-03,\n",
              "        1.8608376e-02], dtype=float32),\n",
              " array([2.0196193e-04, 6.5796470e-05, 3.7401318e-05, 2.4453025e-06,\n",
              "        1.3323055e-04, 1.3195192e-04, 1.8257071e-03, 1.0135131e-03,\n",
              "        8.6692598e-04, 1.6444862e-03, 4.6494566e-03, 2.1887433e-03,\n",
              "        3.2773794e-04], dtype=float32),\n",
              " array([4.9730187e-04, 1.4264522e-04, 8.6243796e-05, 9.6116764e-06,\n",
              "        2.4341034e-05, 5.2603515e-05, 3.0370490e-04, 1.0670285e-03,\n",
              "        3.3196926e-04, 1.6841002e-02, 3.2112616e-01, 1.7068239e-03,\n",
              "        7.7132747e-02], dtype=float32),\n",
              " array([3.12642485e-04, 4.72960179e-04, 6.66909837e-05, 1.13527167e-05,\n",
              "        4.53620851e-05, 1.55077738e-04, 2.57809705e-04, 1.35036433e-04,\n",
              "        1.65306250e-04, 1.28267595e-04, 1.19397315e-04, 4.92151730e-06,\n",
              "        6.17052056e-03], dtype=float32),\n",
              " array([1.0568965e-05, 4.0915969e-05, 3.3385728e-05, 4.0254323e-05,\n",
              "        1.1049378e-04, 9.5484327e-05, 1.5161109e-04, 4.6118526e-04,\n",
              "        6.1874470e-04, 1.1295367e-03, 1.0435020e-03, 1.0632935e-04,\n",
              "        5.0253695e-01], dtype=float32),\n",
              " array([5.3977292e-06, 5.6641700e-05, 3.5501933e-05, 7.9875354e-06,\n",
              "        5.7576985e-05, 4.7789883e-05, 4.7835394e-05, 4.6674531e-06,\n",
              "        1.4535089e-05, 1.6530948e-05, 3.3887261e-07, 1.1100651e-07,\n",
              "        1.8212924e-05], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA5Q3PbfO4GF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce2366a9-7adb-40f7-a1a4-50f69b0bce5b"
      },
      "source": [
        "print(connectivity(encoder_input_data[20:21],3,False)[0])\n",
        "\n",
        "\n",
        "print(input_texts[20])"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[190  60]\n",
            "(190, 60)\n",
            "போர்ஸ்\n",
            "\n",
            "force\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "q5TFnm7RqNYr",
        "outputId": "9e3c5622-fe04-4774-afda-0f84079e6ed3"
      },
      "source": [
        "res"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'அகற்றினார்\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4tx_C7fM1Lo"
      },
      "source": [
        "Connectivity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiVk1YxLMyZ7"
      },
      "source": [
        "def visualize(output_values, result_list, input):\n",
        "  text_colours = []\n",
        "  for j in range(len(result_list)):\n",
        "    text_colours = []\n",
        "\n",
        "    for i in range(len(input)):\n",
        "      text = (input[i], get_clr(output_values[j][i]))\n",
        "      print(output_values[j][i])\n",
        "      text_colours.append(text)\n",
        "    print_color(text_colours)"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixSm56aKkoCS"
      },
      "source": [
        "from IPython.display import HTML as html_print\n",
        "from IPython.display import display"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSdy31p5kss8"
      },
      "source": [
        "def cstr(s, color='black'):\n",
        "\tif s == ' ':\n",
        "\t\treturn \"<text style=color:#000;padding-left:10px;background-color:{}> </text>\".format(color, s)\n",
        "\telse:\n",
        "\t\treturn \"<text style=color:#000;background-color:{}>{} </text>\".format(color, s)\n",
        "\t\n",
        "\n",
        "\n",
        "def get_clr(value):\n",
        "\tcolors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8'\n",
        "\t\t'#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
        "\t\t'#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
        "\t\t'#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
        "\tvalue = int((value * 100) / 5)\n",
        "\treturn colors[value]\n",
        "\n",
        "def print_color(t):\n",
        "\tdisplay(html_print(''.join([cstr(ti, color=ci) for ti,ci in t])))\n",
        "\n",
        "def sigmoid(x):\n",
        "\tz = 1/(1 + np.exp(-x)) \n",
        "\treturn z"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7CofofCjkYHG",
        "outputId": "60388595-c0b3-4bf4-9f9d-d3c75e23b0a2"
      },
      "source": [
        "visualize(vis, res, val_input_texts[10:11][0])"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.07692308\n",
            "0.07692308\n",
            "0.07692308\n",
            "0.07692308\n",
            "0.07692308\n",
            "0.07692308\n",
            "0.07692308\n",
            "0.07692308\n",
            "0.07692308\n",
            "0.07692308\n",
            "0.07692308\n",
            "0.07692308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>g </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>i </text><text style=color:#000;background-color:#89c4e2>n </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>r </text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.076923154\n",
            "0.076923095\n",
            "0.076923095\n",
            "0.076923065\n",
            "0.076923065\n",
            "0.076923065\n",
            "0.076923065\n",
            "0.076923065\n",
            "0.076923065\n",
            "0.076923065\n",
            "0.076923065\n",
            "0.076923065\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>g </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>i </text><text style=color:#000;background-color:#89c4e2>n </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>r </text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.07692169\n",
            "0.07691077\n",
            "0.076914944\n",
            "0.076910675\n",
            "0.07691048\n",
            "0.07691049\n",
            "0.07691052\n",
            "0.07691678\n",
            "0.076910675\n",
            "0.0769145\n",
            "0.07697944\n",
            "0.076912545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>g </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>i </text><text style=color:#000;background-color:#89c4e2>n </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>r </text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.07579895\n",
            "0.07578868\n",
            "0.07581102\n",
            "0.07578918\n",
            "0.075788766\n",
            "0.075788684\n",
            "0.07578911\n",
            "0.07583121\n",
            "0.07579156\n",
            "0.07598984\n",
            "0.087609544\n",
            "0.07613683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>g </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>i </text><text style=color:#000;background-color:#89c4e2>n </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>r </text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.07692206\n",
            "0.07692203\n",
            "0.07692207\n",
            "0.07692203\n",
            "0.076922044\n",
            "0.07692205\n",
            "0.07692213\n",
            "0.0769227\n",
            "0.07692217\n",
            "0.076924056\n",
            "0.07692935\n",
            "0.076922566\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>g </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>i </text><text style=color:#000;background-color:#89c4e2>n </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>r </text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.075795256\n",
            "0.07577633\n",
            "0.07578076\n",
            "0.075775325\n",
            "0.07577523\n",
            "0.07577525\n",
            "0.0757754\n",
            "0.07578155\n",
            "0.07577678\n",
            "0.075907335\n",
            "0.08898769\n",
            "0.07589459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>g </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>i </text><text style=color:#000;background-color:#89c4e2>n </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>r </text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.07686112\n",
            "0.07685066\n",
            "0.07684848\n",
            "0.07684579\n",
            "0.07685584\n",
            "0.07685574\n",
            "0.07698602\n",
            "0.07692353\n",
            "0.076912254\n",
            "0.07697208\n",
            "0.07720373\n",
            "0.07701397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>g </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>i </text><text style=color:#000;background-color:#89c4e2>n </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>r </text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.074220486\n",
            "0.074194156\n",
            "0.07418998\n",
            "0.0741843\n",
            "0.07418539\n",
            "0.07418748\n",
            "0.074206114\n",
            "0.07426278\n",
            "0.07420821\n",
            "0.075443484\n",
            "0.10227538\n",
            "0.0743103\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>g </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>i </text><text style=color:#000;background-color:#89c4e2>n </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#95cae5>a </text><text style=color:#000;background-color:#89c4e2>r </text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.076899424\n",
            "0.07691176\n",
            "0.07688052\n",
            "0.07687626\n",
            "0.07687888\n",
            "0.07688731\n",
            "0.076895215\n",
            "0.076885775\n",
            "0.0768881\n",
            "0.07688525\n",
            "0.076884575\n",
            "0.076875776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>g </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>i </text><text style=color:#000;background-color:#89c4e2>n </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>r </text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.07322463\n",
            "0.07322685\n",
            "0.073226295\n",
            "0.0732268\n",
            "0.07323194\n",
            "0.07323084\n",
            "0.07323495\n",
            "0.073257625\n",
            "0.07326917\n",
            "0.0733066\n",
            "0.073300295\n",
            "0.07323164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>g </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>i </text><text style=color:#000;background-color:#89c4e2>n </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>r </text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.07692166\n",
            "0.0769256\n",
            "0.07692397\n",
            "0.07692186\n",
            "0.07692567\n",
            "0.076924905\n",
            "0.076924905\n",
            "0.07692159\n",
            "0.07692235\n",
            "0.076922506\n",
            "0.07692126\n",
            "0.07692125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>g </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#89c4e2>i </text><text style=color:#000;background-color:#89c4e2>n </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#89c4e2>r </text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Tk-W_X6ykd0U",
        "outputId": "3bbdd226-1fa2-4682-ead0-1c1dfd18ec46"
      },
      "source": [
        "val_input_texts[20:21][0]"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'angkeekaaraththai'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_hYCLx6ltuj",
        "outputId": "d09c67d3-9706-4f08-de2d-fad320fa0151"
      },
      "source": [
        "np.shape(vis)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2LY-qhao-Co"
      },
      "source": [
        "def sm(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq8dxxoomSlI"
      },
      "source": [
        "for i in range(len(vis)):\n",
        "  vis[i]=sm(vis[i])"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrIJ4MlVmfZo",
        "outputId": "31f14bac-5955-4cef-8068-de38f23685a0"
      },
      "source": [
        "vis"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.07692308, 0.07692308, 0.07692308, 0.07692308, 0.07692308,\n",
              "        0.07692308, 0.07692308, 0.07692308, 0.07692308, 0.07692308,\n",
              "        0.07692308, 0.07692308, 0.07692308], dtype=float32),\n",
              " array([0.07692315, 0.07692309, 0.07692309, 0.07692306, 0.07692306,\n",
              "        0.07692306, 0.07692306, 0.07692306, 0.07692306, 0.07692306,\n",
              "        0.07692306, 0.07692306, 0.07692306], dtype=float32),\n",
              " array([0.07692169, 0.07691077, 0.07691494, 0.07691067, 0.07691048,\n",
              "        0.07691049, 0.07691052, 0.07691678, 0.07691067, 0.0769145 ,\n",
              "        0.07697944, 0.07691254, 0.07697652], dtype=float32),\n",
              " array([0.07579895, 0.07578868, 0.07581102, 0.07578918, 0.07578877,\n",
              "        0.07578868, 0.07578911, 0.07583121, 0.07579156, 0.07598984,\n",
              "        0.08760954, 0.07613683, 0.07808656], dtype=float32),\n",
              " array([0.07692206, 0.07692203, 0.07692207, 0.07692203, 0.07692204,\n",
              "        0.07692205, 0.07692213, 0.0769227 , 0.07692217, 0.07692406,\n",
              "        0.07692935, 0.07692257, 0.07692465], dtype=float32),\n",
              " array([0.07579526, 0.07577633, 0.07578076, 0.07577533, 0.07577523,\n",
              "        0.07577525, 0.0757754 , 0.07578155, 0.07577678, 0.07590733,\n",
              "        0.08898769, 0.07589459, 0.07719842], dtype=float32),\n",
              " array([0.07686112, 0.07685066, 0.07684848, 0.07684579, 0.07685584,\n",
              "        0.07685574, 0.07698602, 0.07692353, 0.07691225, 0.07697208,\n",
              "        0.07720373, 0.07701397, 0.07687079], dtype=float32),\n",
              " array([0.07422049, 0.07419416, 0.07418998, 0.0741843 , 0.07418539,\n",
              "        0.07418748, 0.07420611, 0.07426278, 0.07420821, 0.07544348,\n",
              "        0.10227538, 0.0743103 , 0.08013202], dtype=float32),\n",
              " array([0.07689942, 0.07691176, 0.07688052, 0.07687626, 0.07687888,\n",
              "        0.07688731, 0.07689521, 0.07688577, 0.0768881 , 0.07688525,\n",
              "        0.07688458, 0.07687578, 0.07735121], dtype=float32),\n",
              " array([0.07322463, 0.07322685, 0.0732263 , 0.0732268 , 0.07323194,\n",
              "        0.07323084, 0.07323495, 0.07325763, 0.07326917, 0.0733066 ,\n",
              "        0.07330029, 0.07323164, 0.12103237], dtype=float32),\n",
              " array([0.07692166, 0.0769256 , 0.07692397, 0.07692186, 0.07692567,\n",
              "        0.07692491, 0.07692491, 0.07692159, 0.07692235, 0.07692251,\n",
              "        0.07692126, 0.07692125, 0.07692263], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mui7EaNgpZgF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}